{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1', '0.15.2', 'cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch import nn\n",
    "import torchvision  # 图片、视频处理\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "torch.__version__, torchvision.__version__, device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToTensor: \n",
    "- 1、输入转为Tensor，\n",
    "- 2、图片格式为 channel, height, width; \n",
    "- 3、像素取值范围规范到0/1\n",
    "\n",
    "torch.utils.data.DataLoader, 作用：\n",
    "- 乱序， shuffle 默认为 True\n",
    "- 将数据采样为小批次， batch_size. batch太小会导致loss的剧烈震荡，太大则内存放不下，也会跨度过大，失去准确性；\n",
    "- num_workers, 子进程设置，更多进程参与\n",
    "- 设置批次处理函数 collate_fn, 用在文本等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.MNIST('data', \n",
    "                                      train=True, \n",
    "                                      download=True, \n",
    "                                      transform=ToTensor())\n",
    "test_ds = torchvision.datasets.MNIST('data', \n",
    "                                     train=False , \n",
    "                                     download=True, \n",
    "                                     transform=ToTensor())\n",
    "# test_ds = test_ds.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)  # batch_size开始为64,可能是最佳，或128\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 28, 28]), torch.Size([2]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_dl))   # train dataloder 可以分解出X和Ydata\n",
    "imgs.shape, labels.shape   # 1: 黑白图片， 28x28的图片分辨率， 64张\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i, img in enumerate( imgs[:5] ): #取前10张图片   \n",
    "    print( img.shape)       # img 被切片，降维了。\n",
    "    npimg = img.numpy()         \n",
    "    npimg = np.squeeze( npimg )  # 从1x28x28 变为 28x28， 1维的被 squeeze 删除\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(npimg)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(x) = max(x, 0)\n",
    "# input = torch.randint(2,[2,3,4])\n",
    "input = torch.randn(5)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, torch.relu(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input,torch.sigmoid( input )\n",
    "input,torch.tanh( input )\n",
    "input,nn.LeakyReLU( input )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是数据准备和模式测试， \n",
    "以下正式开始设计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层感知器模型， 添加1个隐藏层，\n",
    "class Model( nn.Module ):   # 从nn类初始化\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 初始化父类属性\n",
    "        self.linear_1 = nn.Linear(28*28, 120)  # 全连接层、线性层，； 要求输入数据是1维的，所以[1, 28, 28]被压缩到1层28*28；view()\n",
    "        self.linear_2 = nn.Linear(120, 84)  # 线性层， \n",
    "        self.linear_3 = nn.Linear(84, 10)  # 线性层， \n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 1*28*28)\n",
    "        x = torch.relu(self.linear_1(x))\n",
    "        x = torch.relu(self.linear_2(x))\n",
    "        logits = self.linear_3(x)            # 第3层不做激活函数， 算出在10个分量上，可能值最大的分量，就定义为分量的标签值。即哪个标签分量值最大，就是那个数字。\n",
    "        return logits                         # logits: 一般指未激活前的输出2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- target： 0,1,2,3.。。 并不是一个独热编码的形式？\n",
    "- input： logits\n",
    "- output：？\n",
    "\"\"\"\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "# input = torch.randn(5)\n",
    "# input, np.argmax(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "优化： 根据计算得到的损失，调整模型参数， 降低损失的过程；\n",
    "- Adam 优化器\n",
    "- SGD：优化model的参数、以及lr\n",
    "\"\"\"\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "训练循环：计算准确率correect， 以及每个批次的平均loss\n",
    "\"\"\"\n",
    "def train(dl, model, loss_fn, optimizer):\n",
    "    size = len( dl.dataset )    # 数据多少？\n",
    "    num_batches = len(dl)       # 返回训练批次\n",
    "    train_loss, correct = 0, 0 # 每个批次累计的loss之和， 正确的样本数累计\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)     # 按照损失函数，计算损失\n",
    "        optimizer.zero_grad()       # 清零后计算新的loop的梯度；\n",
    "        loss.backward()             # 按照loss，反向计算梯度；\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            # pred是2维，0维是batch数，1维才是0-9的logits输出；boll转换为float32，累计;item转换到python\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()  \n",
    "            train_loss += loss.item()\n",
    "    correct /= size\n",
    "    train_loss /= num_batches      # losss是以每个批次计算，correct是以个数计算；所以分母不同；\n",
    "    return correct, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试函数: 计算准确率correect， 以及每个批次的平均loss\n",
    "def test(test_dl, model, loss_fn):\n",
    "    size = len( test_dl.dataset )    # 数据多少？\n",
    "    num_batches = len(test_dl)       # 返回训练批次\n",
    "    test_loss, correct = 0, 0 # 每个批次累计的loss之和， 正确的样本数累计\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)     # 按照损失函数，计算损失\n",
    "            test_loss += loss.item()\n",
    "            # pred是2维，0维是batch数，1维才是0-9的logits输出；boll转换为float32，累计;item转换到python\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()  \n",
    "        correct /= size\n",
    "        test_loss /= num_batches      # losss是以每个批次计算，correct是以个数计算；所以分母不同；\n",
    "        return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    训练 50 个 epoch， 记录每个epoch的train和test的损失、准确率。 \n",
    "\"\"\"\n",
    "# batch_size 非常关键：4096不准确； 64很准确。16也比较差。 ！！！\n",
    "def fit(epochs, train_dl, test_dl, model, loss_fn, opt ):\n",
    "    # epochs = 20\n",
    "    train_loss, train_acc = [], []\n",
    "    test_loss,  test_acc  = [], []\n",
    "\n",
    "    for epoch in range( epochs ):\n",
    "        epoch_acc, epoch_loss = train( train_dl, model, loss_fn, opt)\n",
    "        epoch_test_acc, epoch_test_loss = test( test_dl, model, loss_fn)\n",
    "        train_acc.append(epoch_acc)\n",
    "        train_loss.append(epoch_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        test_loss.append(epoch_test_loss)  # 记录、图表化后，观察是否会过拟合等问题\n",
    "        \n",
    "        template = (\"epoch:{:2d}, train_Loss:{:.5f}, train_acc:{:.2f}, test_Loss:{:.5f}, test_acc:{:.2f}, \")\n",
    "        print(template.format( epoch, epoch_loss, epoch_acc*100, epoch_test_loss, epoch_test_acc*100))\n",
    "    print('Done')\n",
    "    return train_loss, train_acc, test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# batch_size = 64   \n",
    "# batch_size = 128\n",
    "batch_size = 4096\n",
    "epochs = 200\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)  # batch_size开始为64\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "train_loss, train_acc, test_loss, test_acc = fit(epochs,train_dl, test_dl, model, loss_fn, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( range(epochs), train_loss, label='train_loss')\n",
    "plt.plot( range(epochs), test_loss, label='test_loss')\n",
    "plt.legend()\n",
    "# train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( range(epochs), train_acc, label='train_acc')\n",
    "plt.plot( range(epochs), test_acc, label='test_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
