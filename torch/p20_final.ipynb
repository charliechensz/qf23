{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../dataset/hr_train.csv\")\n",
    "# df.head()\n",
    "# df.info()\n",
    "# df.sales.unique()\n",
    "# df.salary.unique()\n",
    "# df.groupby(['salary', 'sales']).size()\n",
    "\n",
    "# pd.get_dummies(df.salary)\n",
    "# df = df.join(pd.get_dummies(df.salary))\n",
    "# del df['salary']\n",
    "\n",
    "# pd.get_dummies(df.sales)  # 读日编码？？？\n",
    "# df = df.rename(columns={'sales':'department'})\n",
    "# df = df.join(pd.get_dummies(df.department))\n",
    "# del df['department']\n",
    "# df.to_csv(\"../dataset/hr_train_ok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>...</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>accounting</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.75             0.81               5                   227   \n",
       "1                0.13             0.91               2                   149   \n",
       "2                0.67             0.74               3                   226   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  high  low  \\\n",
       "0                   5              0     1                      0     0    0   \n",
       "1                   5              0     0                      0     0    0   \n",
       "2                   3              0     0                      0     0    1   \n",
       "\n",
       "   ...  IT  RandD  accounting  hr  management  marketing  product_mng  sales  \\\n",
       "0  ...   0      0           0   0           0          0            0      0   \n",
       "1  ...   0      0           0   0           0          0            0      1   \n",
       "2  ...   0      0           0   0           0          0            1      0   \n",
       "\n",
       "   support  technical  \n",
       "0        0          1  \n",
       "1        0          0  \n",
       "2        0          0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../dataset/hr_test_ok.csv\")\n",
    "df = pd.read_csv(\"../dataset/hr_train_ok.csv\")\n",
    "del df['id']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11999 entries, 0 to 11998\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     11999 non-null  float64\n",
      " 1   last_evaluation        11999 non-null  float64\n",
      " 2   number_project         11999 non-null  int64  \n",
      " 3   average_montly_hours   11999 non-null  int64  \n",
      " 4   time_spend_company     11999 non-null  int64  \n",
      " 5   Work_accident          11999 non-null  int64  \n",
      " 6   left                   11999 non-null  int64  \n",
      " 7   promotion_last_5years  11999 non-null  int64  \n",
      " 8   high                   11999 non-null  int64  \n",
      " 9   low                    11999 non-null  int64  \n",
      " 10  medium                 11999 non-null  int64  \n",
      " 11  IT                     11999 non-null  int64  \n",
      " 12  RandD                  11999 non-null  int64  \n",
      " 13  accounting             11999 non-null  int64  \n",
      " 14  hr                     11999 non-null  int64  \n",
      " 15  management             11999 non-null  int64  \n",
      " 16  marketing              11999 non-null  int64  \n",
      " 17  product_mng            11999 non-null  int64  \n",
      " 18  sales                  11999 non-null  int64  \n",
      " 19  support                11999 non-null  int64  \n",
      " 20  technical              11999 non-null  int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11999, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.left.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9129\n",
       "1    2870\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.left.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
       "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
       "       'promotion_last_5years', 'high', 'low', 'medium', 'IT', 'RandD',\n",
       "       'accounting', 'hr', 'management', 'marketing', 'product_mng', 'sales',\n",
       "       'support', 'technical'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "11994    0\n",
       "11995    0\n",
       "11996    0\n",
       "11997    0\n",
       "11998    0\n",
       "Name: left, Length: 11999, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.left   # 输出的不是pd，只是列\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = df.left.values.reshape(-1,1)  # 转换成 pd type array\n",
    "Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11999, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y = torch.from_numpy(Y_data).type(torch.float32)  # 转换成tensor\n",
    "Y = torch.from_numpy(Y_data).type(torch.FloatTensor)\n",
    "Y.shape\n",
    "# Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11999, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = [c for c in df.columns if c != 'left']\n",
    "X_data = df[X_columns]  \n",
    "# X = torch.from_numpy(X_data.values).type(torch.FloatTensor)\n",
    "X = torch.from_numpy(X_data.values).type(torch.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # 避免relu和sigmoid的初始化，可以直接调用\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(20, 64)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(64, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.sigmoid( self.liner_3(x) )\n",
    "        return x\n",
    "\n",
    "# 更加高级语言法，等价于Model\n",
    "class Model_high(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(20, 64)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(64, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.Liner_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "def get_model():\n",
    "    model = Model()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (liner_1): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (liner_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (liner_3): Linear(in_features=64, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, optim = get_model()\n",
    "print( model, \"\\n\" )\n",
    "print( optim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "batch = 1024\n",
    "no_of_batches = len(X)//batch\n",
    "epochs = 30\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 4.1 - random_split Mode， charlie\n",
    "# from torch.utils.data import random_split    \n",
    "# def accuracy(y_pred, y_true):\n",
    "#     y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "#     acc = (y_pred == y_true).float().mean()\n",
    "#     return acc\n",
    "\n",
    "# HR_dataset = TensorDataset(X, Y)\n",
    "# test_ds, test_ds = random_split(HR_dataset, [0.8, 0.2]) \n",
    "# HR_dataloader = DataLoader(test_ds, batch_size=batch, shuffle=True)  # shuffle乱序取数\n",
    "# epochMode = 41\n",
    "# if epochMode == 41:  \n",
    "#     for epoch in range( epochs ):\n",
    "#         # for x,y in HR_dataloader:\n",
    "#         for x,y in HR_dataloader:\n",
    "#             y_pred = model(x)\n",
    "#             loss = loss_fn(y_pred, y)\n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#         with torch.no_grad():\n",
    "#             print('epoch: ', epoch, ' loss: ', loss_fn(model(X), Y).data.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 4.2 - sklearn mode\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape\n",
    "\n",
    "train_x = torch.from_numpy(train_x.values).type(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32)\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_x = torch.from_numpy(test_x.values).type(torch.float32)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32)\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)  # 不需要shuffle，减少运算量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正确率\n",
    "- Sigmoid()是0和1之间的值， 大于0.5为1，否则是0\n",
    "- out1 = (y-pred >0.5).type(torch.int32)  : 转换成0或1\n",
    "- (out1 == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  train_loss:  0.5793  Acc： 0.7568 0  test_loss:  0.5662  Acc： 0.773\n",
      "epoch:  1  train_loss:  0.5671  Acc： 0.7568 1  test_loss:  0.5467  Acc： 0.773\n",
      "epoch:  2  train_loss:  0.5684  Acc： 0.7568 2  test_loss:  0.5462  Acc： 0.773\n",
      "epoch:  3  train_loss:  0.5677  Acc： 0.7568 3  test_loss:  0.5498  Acc： 0.773\n",
      "epoch:  4  train_loss:  0.5667  Acc： 0.7568 4  test_loss:  0.5463  Acc： 0.773\n",
      "epoch:  5  train_loss:  0.5665  Acc： 0.7568 5  test_loss:  0.5464  Acc： 0.773\n",
      "epoch:  6  train_loss:  0.5664  Acc： 0.7568 6  test_loss:  0.5475  Acc： 0.773\n",
      "epoch:  7  train_loss:  0.5661  Acc： 0.7568 7  test_loss:  0.5466  Acc： 0.773\n",
      "epoch:  8  train_loss:  0.566  Acc： 0.7568 8  test_loss:  0.5461  Acc： 0.773\n",
      "epoch:  9  train_loss:  0.5658  Acc： 0.7568 9  test_loss:  0.5461  Acc： 0.773\n",
      "epoch:  10  train_loss:  0.5656  Acc： 0.7568 10  test_loss:  0.546  Acc： 0.773\n",
      "epoch:  11  train_loss:  0.5655  Acc： 0.7568 11  test_loss:  0.5454  Acc： 0.773\n",
      "epoch:  12  train_loss:  0.5653  Acc： 0.7568 12  test_loss:  0.5456  Acc： 0.773\n",
      "epoch:  13  train_loss:  0.5651  Acc： 0.7568 13  test_loss:  0.5455  Acc： 0.773\n",
      "epoch:  14  train_loss:  0.565  Acc： 0.7568 14  test_loss:  0.545  Acc： 0.773\n",
      "epoch:  15  train_loss:  0.5648  Acc： 0.7568 15  test_loss:  0.5455  Acc： 0.773\n",
      "epoch:  16  train_loss:  0.5646  Acc： 0.7568 16  test_loss:  0.5455  Acc： 0.773\n",
      "epoch:  17  train_loss:  0.5645  Acc： 0.7568 17  test_loss:  0.5443  Acc： 0.773\n",
      "epoch:  18  train_loss:  0.5643  Acc： 0.7568 18  test_loss:  0.5454  Acc： 0.773\n",
      "epoch:  19  train_loss:  0.5647  Acc： 0.7568 19  test_loss:  0.5435  Acc： 0.773\n",
      "epoch:  20  train_loss:  0.5641  Acc： 0.7568 20  test_loss:  0.5456  Acc： 0.773\n",
      "epoch:  21  train_loss:  0.5637  Acc： 0.7568 21  test_loss:  0.5436  Acc： 0.773\n",
      "epoch:  22  train_loss:  0.5641  Acc： 0.7568 22  test_loss:  0.5463  Acc： 0.773\n",
      "epoch:  23  train_loss:  0.5635  Acc： 0.7568 23  test_loss:  0.543  Acc： 0.773\n",
      "epoch:  24  train_loss:  0.5632  Acc： 0.7568 24  test_loss:  0.5446  Acc： 0.773\n",
      "epoch:  25  train_loss:  0.5628  Acc： 0.7568 25  test_loss:  0.5432  Acc： 0.773\n",
      "epoch:  26  train_loss:  0.5627  Acc： 0.7568 26  test_loss:  0.5438  Acc： 0.773\n",
      "epoch:  27  train_loss:  0.5624  Acc： 0.7568 27  test_loss:  0.5431  Acc： 0.773\n",
      "epoch:  28  train_loss:  0.5623  Acc： 0.7568 28  test_loss:  0.5434  Acc： 0.773\n",
      "epoch:  29  train_loss:  0.562  Acc： 0.7568 29  test_loss:  0.543  Acc： 0.773\n",
      "epoch:  30  train_loss:  0.5619  Acc： 0.7568 30  test_loss:  0.5419  Acc： 0.773\n",
      "epoch:  31  train_loss:  0.562  Acc： 0.7568 31  test_loss:  0.5441  Acc： 0.773\n",
      "epoch:  32  train_loss:  0.5613  Acc： 0.7568 32  test_loss:  0.5417  Acc： 0.773\n",
      "epoch:  33  train_loss:  0.5611  Acc： 0.7568 33  test_loss:  0.5414  Acc： 0.773\n",
      "epoch:  34  train_loss:  0.5611  Acc： 0.7568 34  test_loss:  0.5428  Acc： 0.773\n",
      "epoch:  35  train_loss:  0.5608  Acc： 0.7568 35  test_loss:  0.5407  Acc： 0.773\n",
      "epoch:  36  train_loss:  0.5605  Acc： 0.7568 36  test_loss:  0.5421  Acc： 0.773\n",
      "epoch:  37  train_loss:  0.5601  Acc： 0.7568 37  test_loss:  0.5412  Acc： 0.773\n",
      "epoch:  38  train_loss:  0.56  Acc： 0.7568 38  test_loss:  0.5401  Acc： 0.773\n",
      "epoch:  39  train_loss:  0.5596  Acc： 0.7568 39  test_loss:  0.5402  Acc： 0.773\n",
      "epoch:  40  train_loss:  0.5597  Acc： 0.7568 40  test_loss:  0.5417  Acc： 0.773\n",
      "epoch:  41  train_loss:  0.5593  Acc： 0.7568 41  test_loss:  0.5393  Acc： 0.773\n",
      "epoch:  42  train_loss:  0.5588  Acc： 0.7568 42  test_loss:  0.5399  Acc： 0.773\n",
      "epoch:  43  train_loss:  0.5588  Acc： 0.7568 43  test_loss:  0.5408  Acc： 0.773\n",
      "epoch:  44  train_loss:  0.5585  Acc： 0.7568 44  test_loss:  0.5387  Acc： 0.773\n",
      "epoch:  45  train_loss:  0.5582  Acc： 0.7568 45  test_loss:  0.5398  Acc： 0.773\n",
      "epoch:  46  train_loss:  0.5579  Acc： 0.7568 46  test_loss:  0.5393  Acc： 0.773\n",
      "epoch:  47  train_loss:  0.558  Acc： 0.7568 47  test_loss:  0.5377  Acc： 0.773\n",
      "epoch:  48  train_loss:  0.5575  Acc： 0.7568 48  test_loss:  0.5395  Acc： 0.773\n",
      "epoch:  49  train_loss:  0.5572  Acc： 0.7568 49  test_loss:  0.5374  Acc： 0.773\n",
      "epoch:  50  train_loss:  0.5567  Acc： 0.7568 50  test_loss:  0.5376  Acc： 0.773\n",
      "epoch:  51  train_loss:  0.5565  Acc： 0.7568 51  test_loss:  0.5373  Acc： 0.773\n",
      "epoch:  52  train_loss:  0.5569  Acc： 0.7568 52  test_loss:  0.5363  Acc： 0.773\n",
      "epoch:  53  train_loss:  0.5564  Acc： 0.7568 53  test_loss:  0.539  Acc： 0.773\n",
      "epoch:  54  train_loss:  0.5568  Acc： 0.7568 54  test_loss:  0.5358  Acc： 0.773\n",
      "epoch:  55  train_loss:  0.5574  Acc： 0.7568 55  test_loss:  0.5414  Acc： 0.773\n",
      "epoch:  56  train_loss:  0.5563  Acc： 0.7568 56  test_loss:  0.5352  Acc： 0.773\n",
      "epoch:  57  train_loss:  0.5571  Acc： 0.7568 57  test_loss:  0.5414  Acc： 0.773\n",
      "epoch:  58  train_loss:  0.5554  Acc： 0.7568 58  test_loss:  0.5347  Acc： 0.773\n",
      "epoch:  59  train_loss:  0.5547  Acc： 0.7568 59  test_loss:  0.5375  Acc： 0.773\n",
      "epoch:  60  train_loss:  0.5541  Acc： 0.7568 60  test_loss:  0.5366  Acc： 0.773\n",
      "epoch:  61  train_loss:  0.5543  Acc： 0.7568 61  test_loss:  0.5339  Acc： 0.773\n",
      "epoch:  62  train_loss:  0.5553  Acc： 0.7568 62  test_loss:  0.5394  Acc： 0.773\n",
      "epoch:  63  train_loss:  0.5539  Acc： 0.7568 63  test_loss:  0.5333  Acc： 0.773\n",
      "epoch:  64  train_loss:  0.5527  Acc： 0.7568 64  test_loss:  0.5347  Acc： 0.773\n",
      "epoch:  65  train_loss:  0.5524  Acc： 0.7568 65  test_loss:  0.5346  Acc： 0.773\n",
      "epoch:  66  train_loss:  0.5521  Acc： 0.7568 66  test_loss:  0.5342  Acc： 0.773\n",
      "epoch:  67  train_loss:  0.5517  Acc： 0.7568 67  test_loss:  0.5327  Acc： 0.773\n",
      "epoch:  68  train_loss:  0.5513  Acc： 0.7568 68  test_loss:  0.5329  Acc： 0.773\n",
      "epoch:  69  train_loss:  0.5517  Acc： 0.7568 69  test_loss:  0.535  Acc： 0.773\n",
      "epoch:  70  train_loss:  0.5518  Acc： 0.7568 70  test_loss:  0.5312  Acc： 0.773\n",
      "epoch:  71  train_loss:  0.5504  Acc： 0.7568 71  test_loss:  0.5327  Acc： 0.773\n",
      "epoch:  72  train_loss:  0.5499  Acc： 0.7568 72  test_loss:  0.5313  Acc： 0.773\n",
      "epoch:  73  train_loss:  0.5501  Acc： 0.7568 73  test_loss:  0.5303  Acc： 0.773\n",
      "epoch:  74  train_loss:  0.5495  Acc： 0.7568 74  test_loss:  0.5301  Acc： 0.773\n",
      "epoch:  75  train_loss:  0.5491  Acc： 0.7568 75  test_loss:  0.5317  Acc： 0.773\n",
      "epoch:  76  train_loss:  0.5487  Acc： 0.7568 76  test_loss:  0.5313  Acc： 0.773\n",
      "epoch:  77  train_loss:  0.5481  Acc： 0.7568 77  test_loss:  0.5296  Acc： 0.773\n",
      "epoch:  78  train_loss:  0.5478  Acc： 0.7568 78  test_loss:  0.5298  Acc： 0.773\n",
      "epoch:  79  train_loss:  0.5474  Acc： 0.7568 79  test_loss:  0.5294  Acc： 0.773\n",
      "epoch:  80  train_loss:  0.5471  Acc： 0.7568 80  test_loss:  0.5297  Acc： 0.773\n",
      "epoch:  81  train_loss:  0.5475  Acc： 0.7568 81  test_loss:  0.5275  Acc： 0.773\n",
      "epoch:  82  train_loss:  0.5462  Acc： 0.7568 82  test_loss:  0.5284  Acc： 0.773\n",
      "epoch:  83  train_loss:  0.5458  Acc： 0.7568 83  test_loss:  0.528  Acc： 0.773\n",
      "epoch:  84  train_loss:  0.5455  Acc： 0.7568 84  test_loss:  0.5278  Acc： 0.773\n",
      "epoch:  85  train_loss:  0.5452  Acc： 0.7568 85  test_loss:  0.5263  Acc： 0.773\n",
      "epoch:  86  train_loss:  0.5446  Acc： 0.7568 86  test_loss:  0.5272  Acc： 0.773\n",
      "epoch:  87  train_loss:  0.5445  Acc： 0.7568 87  test_loss:  0.5254  Acc： 0.773\n",
      "epoch:  88  train_loss:  0.5438  Acc： 0.7568 88  test_loss:  0.5264  Acc： 0.773\n",
      "epoch:  89  train_loss:  0.5433  Acc： 0.7568 89  test_loss:  0.5255  Acc： 0.773\n",
      "epoch:  90  train_loss:  0.5441  Acc： 0.7568 90  test_loss:  0.5241  Acc： 0.773\n",
      "epoch:  91  train_loss:  0.5427  Acc： 0.7568 91  test_loss:  0.5259  Acc： 0.773\n",
      "epoch:  92  train_loss:  0.5422  Acc： 0.7568 92  test_loss:  0.5235  Acc： 0.773\n",
      "epoch:  93  train_loss:  0.5427  Acc： 0.7568 93  test_loss:  0.5228  Acc： 0.773\n",
      "epoch:  94  train_loss:  0.5442  Acc： 0.7568 94  test_loss:  0.53  Acc： 0.773\n",
      "epoch:  95  train_loss:  0.5413  Acc： 0.7568 95  test_loss:  0.5221  Acc： 0.773\n",
      "epoch:  96  train_loss:  0.5408  Acc： 0.7568 96  test_loss:  0.5247  Acc： 0.773\n",
      "epoch:  97  train_loss:  0.5404  Acc： 0.7568 97  test_loss:  0.5212  Acc： 0.773\n",
      "epoch:  98  train_loss:  0.5393  Acc： 0.7568 98  test_loss:  0.5216  Acc： 0.773\n",
      "epoch:  99  train_loss:  0.5389  Acc： 0.7568 99  test_loss:  0.5216  Acc： 0.773\n",
      "CPU times: total: 20.7 s\n",
      "Wall time: 9.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (liner_1): Linear(in_features=20, out_features=64, bias=True)\n",
       "  (liner_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (liner_3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 100\n",
    "for epoch in range( epochs ):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch: ', \n",
    "            epoch, ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "            epoch, ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   train_loss:  0.5389  Acc： 0.7568  test_loss:  0.5216  Acc： 0.773\n"
     ]
    }
   ],
   "source": [
    "# 最后一次计算结果：\n",
    "\n",
    "epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "print('epoch: ', \n",
    "    ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "    ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( loss_fn(model(train_x), train_y).data.item() )\n",
    "# accuracyRate = ((model(train_x).data.numpy()).astype('int') == train_y.numpy().astype('int')).mean()\n",
    "# print(\"训练数据 - 准确率%：\", accuracyRate*100) \n",
    "\n",
    "# print( loss_fn(model(test_x), test_y).data.item() )\n",
    "# accuracyRate = ((model(test_x).data.numpy()).astype('int') == test_y.numpy().astype('int')).mean()\n",
    "# print(\"测试数据 - 准确率%：\", accuracyRate*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据准确性验证\n",
    "- 过拟合/欠拟合\n",
    "    - 过拟合：对于已知数据过度拟合，对未知数据预测性差\n",
    "    - 欠拟合：对于已知数据拟合不够，对未知数据预测性差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)\n",
    "# train_x = torch.from_numpy(train_x).type(torch.float32)\n",
    "# test_x = torch.from_numpy(test_x).type(torch.float32)\n",
    "# train_y = torch.from_numpy(train_y).type(torch.float32)\n",
    "# test_y = torch.from_numpy(test_y).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (y_pred == y).float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
