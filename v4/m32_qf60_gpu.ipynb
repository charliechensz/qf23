{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random\n",
    "# %matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F  # 避免relu和sigmoid的初始化，可以直接调用\n",
    "\n",
    "from importlib import reload \n",
    "from qflib import basic\n",
    "reload(basic)\n",
    "\n",
    "global engine, conn\n",
    "engine = basic.engine()\n",
    "conn = basic.conn(engine)\n",
    "\n",
    "df=pd.DataFrame()  # 初始化空值\n",
    "# pd.options.display.float_format = '{:.7g}'.format \n",
    "vTest = 1000\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True  \n",
    "cudnn.deterministic = True\n",
    "\n",
    "xl_01dgree = 0.001745 # 0.1度 \n",
    "xl_02dgree = 0.003490 # 0.2度 \n",
    "xl_03dgree = 0.005230 # 0.3度\n",
    "xl_dgree = xl_03dgree\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( device )\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.caching_allocator_delete\n",
    "#     torch.cuda.empty_cache()  # 释放显存\n",
    "#     print('Memory Allocated', torch.cuda.memory_allocated() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"SELECT * FROM ds_qf60\"\n",
    "# sql=\"SELECT * FROM ds_qf60_2\"\n",
    "df = pd.read_sql_query(sql, conn, index_col=None)\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101148 entries, 0 to 101147\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   pct_change    101148 non-null  float64\n",
      " 1   diff          101148 non-null  float64\n",
      " 2   dea           101148 non-null  float64\n",
      " 3   bar           101148 non-null  float64\n",
      " 4   jx_days_ud60  101148 non-null  int64  \n",
      " 5   jx_xl_250     101148 non-null  float64\n",
      " 6   jx_xl_120     101148 non-null  float64\n",
      " 7   jx_xl_60      101148 non-null  float64\n",
      " 8   jx_xl_20      101148 non-null  float64\n",
      " 9   jx_xl_10      101148 non-null  float64\n",
      " 10  jx_xl_5       101148 non-null  float64\n",
      " 11  jx_zs_5       101148 non-null  int64  \n",
      " 12  jx_zs_10      101148 non-null  int64  \n",
      " 13  jx_zs_20      101148 non-null  int64  \n",
      " 14  jx_zs_60      101148 non-null  int64  \n",
      " 15  lj_fl_1_3     101148 non-null  float64\n",
      " 16  lj_fl_3_10    101148 non-null  float64\n",
      " 17  lj_fl_5_20    101148 non-null  float64\n",
      " 18  lj_fl_20_60   101148 non-null  float64\n",
      " 19  test5_8       101148 non-null  float64\n",
      " 20  test10_10     101148 non-null  float64\n",
      " 21  test20_10     101148 non-null  float64\n",
      " 22  test20_20     101148 non-null  float64\n",
      " 23  test20_30     101148 non-null  int64  \n",
      " 24  ts_code       101148 non-null  object \n",
      " 25  trade_date    101148 non-null  object \n",
      " 26  class0        101148 non-null  float64\n",
      "dtypes: float64(19), int64(6), object(2)\n",
      "memory usage: 20.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (101148, 27))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 确定训练的目标 \"\"\"\n",
    "# df['class0'] = df['test5_8']\n",
    "# df['class0'] = df['test10_10']\n",
    "df['class0'] = df['test20_20']\n",
    "# df['class0'] = df['test20_30']\n",
    "df.info(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]),\n",
       " 0.0    91728\n",
       " 1.0     9420\n",
       " Name: class0, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class0.unique(), df.class0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'diff', 'dea',, \n",
    "X_columns = ['pct_change', \n",
    "             'diff','dea', \n",
    "             'jx_days_ud60', \n",
    "             'jx_xl_250', 'jx_xl_120','jx_xl_60', \n",
    "             'jx_xl_20', 'jx_xl_10', 'jx_xl_5', \n",
    "             'jx_zs_5', 'jx_zs_10','jx_zs_20', 'jx_zs_60', \n",
    "             'lj_fl_1_3', 'lj_fl_3_10', 'lj_fl_5_20','lj_fl_20_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns]  \n",
    "# X = torch.from_numpy(X_data.values).type(torch.float32)\n",
    "Y_data = df.class0.values.reshape(-1,1)  # 转换成 pd type array\n",
    "# Y = torch.from_numpy(Y_data).type(torch.float32)\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_data.class0.unique()\n",
    "# df.class0.value_counts()\n",
    "# Y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(18, 64)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(64, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.sigmoid( self.liner_3(x) )\n",
    "        return x\n",
    "\n",
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(18, 256)   # X.size(1)= 20； 定义256个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 32)   # 接着，再定义32个后续中间层\n",
    "        self.liner_4 = nn.Linear(32, 1)     \n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.relu( self.liner_3(x) )\n",
    "        x = F.sigmoid( self.liner_4(x) )\n",
    "        return x\n",
    "    \n",
    "class Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(18, 256)   # X.size(1)= 20； 定义256个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_4 = nn.Linear(128, 32)   # 接着，再定义32个后续中间层\n",
    "        self.liner_5 = nn.Linear(32, 1)     \n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.relu( self.liner_3(x) )\n",
    "        x = F.relu( self.liner_4(x) )\n",
    "        x = F.sigmoid( self.liner_5(x) )\n",
    "        return x\n",
    "\n",
    "# 更加高级语言法，等价于Model\n",
    "class Model_high(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(29, 256)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_4 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.Liner_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([75861, 18]),\n",
       " torch.Size([25287, 18]),\n",
       " torch.Size([75861, 1]),\n",
       " torch.Size([25287, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver 4.2 - sklearn mode\n",
    "\n",
    "lr = 0.00012\n",
    "def get_model():\n",
    "    model = Model4()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "model, optim = get_model()\n",
    "model = model.to(device)\n",
    "# model, optim \n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = loss_fn.to(device)\n",
    "batch = 32\n",
    "# batch = 64\n",
    "# batch = 1024\n",
    "# batch = 8192\n",
    "# batch = 16384\n",
    "# batch = 32768\n",
    "epochs = 10\n",
    "no_of_batches = len(X_data)//batch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)\n",
    "\n",
    "train_x = torch.from_numpy(train_x.values).type(torch.float32).to(device)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32).to(device)\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_x = torch.from_numpy(test_x.values).type(torch.float32).to(device)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32).to(device)\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)  # 不需要shuffle，减少运算量\n",
    "\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正确率\n",
    "- Sigmoid()是0和1之间的值， 大于0.5为1，否则是0\n",
    "- out1 = (y-pred >0.5).type(torch.int32)  : 转换成0或1\n",
    "- (out1 == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  train_loss:  0.3077  Acc： 0.9075 0  test_loss:  0.3121  Acc： 0.905\n",
      "epoch:  1  train_loss:  0.3083  Acc： 0.9076 1  test_loss:  0.3125  Acc： 0.9048\n",
      "epoch:  2  train_loss:  0.3035  Acc： 0.9075 2  test_loss:  0.3091  Acc： 0.9048\n",
      "epoch:  3  train_loss:  0.3026  Acc： 0.9077 3  test_loss:  0.3084  Acc： 0.9048\n",
      "epoch:  4  train_loss:  0.3021  Acc： 0.9076 4  test_loss:  0.3083  Acc： 0.905\n",
      "epoch:  5  train_loss:  0.3029  Acc： 0.9075 5  test_loss:  0.3095  Acc： 0.9049\n",
      "epoch:  6  train_loss:  0.3016  Acc： 0.9077 6  test_loss:  0.308  Acc： 0.9048\n",
      "epoch:  7  train_loss:  0.3025  Acc： 0.9076 7  test_loss:  0.3086  Acc： 0.9049\n",
      "epoch:  8  train_loss:  0.3011  Acc： 0.9076 8  test_loss:  0.3076  Acc： 0.9049\n",
      "epoch:  9  train_loss:  0.3039  Acc： 0.9075 9  test_loss:  0.3111  Acc： 0.905\n",
      "CPU times: total: 11.4 s\n",
      "Wall time: 49.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# epochs = 10\n",
    "for epoch in range( epochs ):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch: ', \n",
    "            epoch, ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "            epoch, ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9050, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>diff</th>\n",
       "      <th>dea</th>\n",
       "      <th>bar</th>\n",
       "      <th>jx_days_ud60</th>\n",
       "      <th>jx_xl_250</th>\n",
       "      <th>jx_xl_120</th>\n",
       "      <th>jx_xl_60</th>\n",
       "      <th>jx_xl_20</th>\n",
       "      <th>jx_xl_10</th>\n",
       "      <th>...</th>\n",
       "      <th>lj_fl_5_20</th>\n",
       "      <th>lj_fl_20_60</th>\n",
       "      <th>test5_8</th>\n",
       "      <th>test10_10</th>\n",
       "      <th>test20_10</th>\n",
       "      <th>test20_20</th>\n",
       "      <th>test20_30</th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.1538</td>\n",
       "      <td>-0.108607</td>\n",
       "      <td>-0.190289</td>\n",
       "      <td>0.163366</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.00262</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44158</td>\n",
       "      <td>0.865133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20230419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pct_change      diff       dea       bar  jx_days_ud60  jx_xl_250  \\\n",
       "0     -1.1538 -0.108607 -0.190289  0.163366            32  -0.000964   \n",
       "\n",
       "   jx_xl_120  jx_xl_60  jx_xl_20  jx_xl_10  ...  lj_fl_5_20  lj_fl_20_60  \\\n",
       "0   0.001425  -0.00262  0.000591  0.001576  ...     1.44158     0.865133   \n",
       "\n",
       "   test5_8  test10_10  test20_10  test20_20  test20_30    ts_code  trade_date  \\\n",
       "0      0.0        0.0        0.0        0.0          0  000001.SZ    20230419   \n",
       "\n",
       "   class0  \n",
       "0     0.0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT pct_change, diff, dea, jx_days_ud60, jx_xl_250, jx_xl_120, jx_xl_60,jx_xl_20, jx_xl_10, jx_xl_5, jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, sz_max_5, sz_max_10, sz_max_20  from day_zhibiao where trade_date>='20230601' and sz_max_20>20 and jx_days_ud60 > 20 and jx_days_ud60 < 60 and jx_xl_60>-0.00523 and  jx_xl_20>0 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>diff</th>\n",
       "      <th>dea</th>\n",
       "      <th>jx_days_ud60</th>\n",
       "      <th>jx_xl_250</th>\n",
       "      <th>jx_xl_120</th>\n",
       "      <th>jx_xl_60</th>\n",
       "      <th>jx_xl_20</th>\n",
       "      <th>jx_xl_10</th>\n",
       "      <th>jx_xl_5</th>\n",
       "      <th>...</th>\n",
       "      <th>jx_zs_20</th>\n",
       "      <th>jx_zs_60</th>\n",
       "      <th>lj_fl_1_3</th>\n",
       "      <th>lj_fl_3_10</th>\n",
       "      <th>lj_fl_5_20</th>\n",
       "      <th>lj_fl_20_60</th>\n",
       "      <th>sz_max_5</th>\n",
       "      <th>sz_max_10</th>\n",
       "      <th>sz_max_20</th>\n",
       "      <th>class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.023673</td>\n",
       "      <td>-0.026637</td>\n",
       "      <td>47</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>-0.002363</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.213370</td>\n",
       "      <td>1.336500</td>\n",
       "      <td>1.097930</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>5.57342</td>\n",
       "      <td>14.57660</td>\n",
       "      <td>24.0086</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2035</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>-0.039214</td>\n",
       "      <td>46</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.311120</td>\n",
       "      <td>1.183640</td>\n",
       "      <td>0.959407</td>\n",
       "      <td>0.508037</td>\n",
       "      <td>6.48649</td>\n",
       "      <td>12.43240</td>\n",
       "      <td>25.0811</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1345</td>\n",
       "      <td>-0.088344</td>\n",
       "      <td>-0.110241</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.079450</td>\n",
       "      <td>1.247460</td>\n",
       "      <td>1.044810</td>\n",
       "      <td>0.634554</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.60256</td>\n",
       "      <td>24.8397</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0073</td>\n",
       "      <td>-0.275007</td>\n",
       "      <td>-0.439436</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.004597</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.510850</td>\n",
       "      <td>1.186750</td>\n",
       "      <td>1.462440</td>\n",
       "      <td>0.774820</td>\n",
       "      <td>10.85810</td>\n",
       "      <td>21.97900</td>\n",
       "      <td>21.9790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.0166</td>\n",
       "      <td>-0.077677</td>\n",
       "      <td>-0.092900</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>-0.005370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.470630</td>\n",
       "      <td>1.351290</td>\n",
       "      <td>1.151170</td>\n",
       "      <td>0.726595</td>\n",
       "      <td>9.81241</td>\n",
       "      <td>20.77920</td>\n",
       "      <td>20.7792</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-0.8457</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.970544</td>\n",
       "      <td>0.695210</td>\n",
       "      <td>1.051000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>24.30700</td>\n",
       "      <td>46.6951</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.5021</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>-0.007108</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.355980</td>\n",
       "      <td>0.994171</td>\n",
       "      <td>0.665529</td>\n",
       "      <td>1.095800</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.05070</td>\n",
       "      <td>45.4545</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-1.4898</td>\n",
       "      <td>-0.082206</td>\n",
       "      <td>-0.114434</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>-0.001479</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795768</td>\n",
       "      <td>0.824149</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.666445</td>\n",
       "      <td>1.89036</td>\n",
       "      <td>4.63138</td>\n",
       "      <td>21.2665</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.1638</td>\n",
       "      <td>-0.050526</td>\n",
       "      <td>-0.131182</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>1.443570</td>\n",
       "      <td>1.424330</td>\n",
       "      <td>0.653009</td>\n",
       "      <td>2.28945</td>\n",
       "      <td>3.18888</td>\n",
       "      <td>29.0270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1.0762</td>\n",
       "      <td>-0.084662</td>\n",
       "      <td>-0.151346</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.002020</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.221770</td>\n",
       "      <td>1.453820</td>\n",
       "      <td>1.280950</td>\n",
       "      <td>0.610735</td>\n",
       "      <td>1.96560</td>\n",
       "      <td>3.35790</td>\n",
       "      <td>29.2383</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pct_change      diff       dea  jx_days_ud60  jx_xl_250  jx_xl_120  \\\n",
       "0        0.8649  0.023673 -0.026637            47   0.001256   0.000402   \n",
       "1        1.2035  0.004385 -0.039214            46   0.001294   0.001039   \n",
       "2        1.1345 -0.088344 -0.110241            58  -0.000318  -0.000709   \n",
       "3        4.0073 -0.275007 -0.439436            49  -0.000068  -0.001143   \n",
       "4       -4.0166 -0.077677 -0.092900            25  -0.000105  -0.001368   \n",
       "..          ...       ...       ...           ...        ...        ...   \n",
       "257     -0.8457 -0.000933 -0.005873            43   0.000334   0.000549   \n",
       "258      1.5021 -0.002501 -0.007108            42   0.000326   0.000691   \n",
       "259     -1.4898 -0.082206 -0.114434            32   0.000000   0.001041   \n",
       "260      0.1638 -0.050526 -0.131182            43  -0.000458   0.000472   \n",
       "261      1.0762 -0.084662 -0.151346            42  -0.000558   0.000419   \n",
       "\n",
       "     jx_xl_60  jx_xl_20  jx_xl_10   jx_xl_5  ...  jx_zs_20  jx_zs_60  \\\n",
       "0   -0.002363  0.002876  0.001426  0.004800  ...        13         0   \n",
       "1   -0.002358  0.002607  0.000769  0.003727  ...        12         0   \n",
       "2   -0.002467  0.000483 -0.000484  0.002265  ...         1         0   \n",
       "3   -0.004597  0.000185  0.009232  0.009872  ...         3         0   \n",
       "4   -0.001970  0.000141 -0.003517 -0.005370  ...         0         0   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "257 -0.001156  0.001068  0.000214  0.000428  ...         2         0   \n",
       "258 -0.000420  0.000963 -0.001287  0.000428  ...         1         0   \n",
       "259 -0.002094  0.000514 -0.001479 -0.002405  ...         0         0   \n",
       "260 -0.002884  0.000084  0.005594  0.011305  ...         4         0   \n",
       "261 -0.002020  0.000377  0.004347  0.009417  ...         3         0   \n",
       "\n",
       "     lj_fl_1_3  lj_fl_3_10  lj_fl_5_20  lj_fl_20_60  sz_max_5  sz_max_10  \\\n",
       "0     1.213370    1.336500    1.097930     0.525210   5.57342   14.57660   \n",
       "1     1.311120    1.183640    0.959407     0.508037   6.48649   12.43240   \n",
       "2     1.079450    1.247460    1.044810     0.634554   0.00000    1.60256   \n",
       "3     1.510850    1.186750    1.462440     0.774820  10.85810   21.97900   \n",
       "4     1.470630    1.351290    1.151170     0.726595   9.81241   20.77920   \n",
       "..         ...         ...         ...          ...       ...        ...   \n",
       "257   0.720554    0.970544    0.695210     1.051000   0.00000   24.30700   \n",
       "258   1.355980    0.994171    0.665529     1.095800   0.00000   12.05070   \n",
       "259   0.795768    0.824149    0.768519     0.666445   1.89036    4.63138   \n",
       "260   0.985386    1.443570    1.424330     0.653009   2.28945    3.18888   \n",
       "261   1.221770    1.453820    1.280950     0.610735   1.96560    3.35790   \n",
       "\n",
       "     sz_max_20  class0  \n",
       "0      24.0086    True  \n",
       "1      25.0811    True  \n",
       "2      24.8397    True  \n",
       "3      21.9790    True  \n",
       "4      20.7792    True  \n",
       "..         ...     ...  \n",
       "257    46.6951    True  \n",
       "258    45.4545    True  \n",
       "259    21.2665    True  \n",
       "260    29.0270    True  \n",
       "261    29.2383    True  \n",
       "\n",
       "[262 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "column_str = 'pct_change, diff, dea, jx_days_ud60, \\\n",
    "jx_xl_250, jx_xl_120, jx_xl_60,\\\n",
    "jx_xl_20, jx_xl_10, jx_xl_5, \\\n",
    "jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,\\\n",
    "lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, \\\n",
    "sz_max_5, sz_max_10, sz_max_20 '\n",
    "# print(column_str)\n",
    "\n",
    "sql_new= \"SELECT \" + column_str +\" \\\n",
    "from day_zhibiao \\\n",
    "where trade_date>='20230601' and sz_max_20>20 and \\\n",
    "jx_days_ud60 > 20 and jx_days_ud60 < 60 and \\\n",
    "jx_xl_60>-\"+str(xl_dgree)+\" and  \\\n",
    "jx_xl_20>0 \"\n",
    "print(sql_new)\n",
    "\n",
    "df_now = pd.read_sql_query(sql_new, conn)\n",
    "\n",
    "df_now['class0'] = df_now['sz_max_20'] > 20 \n",
    "df_now\n",
    "# df_now[ df_now['class0']==1 ]\n",
    "# df_now[ df['class0'] ]\n",
    "# print( df_now.shape, df_now.head(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9420, 18) (9420, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0004, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_mn = df[ df['class0']==1.0 ]\n",
    "# df_mn = df[ df['class0']!=1.0 ].copy()\n",
    "# df_mn = df_now\n",
    "# df_mn = df\n",
    "\n",
    "X_data = df_mn[X_columns]  \n",
    "Y_data = df_mn.class0.values.reshape(-1,1)  # 转换成 pd type array\n",
    "print( X_data.shape, Y_data.shape )\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data, shuffle=True)\n",
    "# train_x = torch.from_numpy(train_x.values).type(torch.float32).to(device)\n",
    "# train_y = torch.from_numpy(train_y).type(torch.float32).to(device)\n",
    "# train_ds = TensorDataset(train_x, train_y)\n",
    "# train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_X = torch.from_numpy(test_x.values).type(torch.float32).to(device)\n",
    "test_Y = torch.from_numpy(test_y).type(torch.float32).to(device)\n",
    "# test_ds = TensorDataset(test_x, test_y)\n",
    "# test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)  # 不需要shuffle，减少运算量\n",
    "\n",
    "accuracy(model(test_X), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_data\n",
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 模型保存 '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 模型保存 \"\"\"\n",
    "# torch.save( model, '../model/test5-8.pth')\n",
    "# path = '../model/test5-8'\n",
    "# torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optim.state_dict(),\n",
    "#            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = []\n",
    "# for i in range(0,X_app.size(0)):\n",
    "#     list1.append( random.randint(1,1) )\n",
    "# len(list1)\n",
    "# Y_app = torch.tensor( list1 )\n",
    "# Y_app.to(device)\n",
    "# Y_app.reshape(-1,1).size(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = []\n",
    "# for i in range(0,X_app.size(0)):\n",
    "#     list1.append( 1.0 )\n",
    "# Y_app = torch.tensor( list1).type(torch.float32).reshape(-1,1).to(device)\n",
    "# Y_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_app = torch.tensor( list1).type(torch.float32)\n",
    "# X_app.shape, Y_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( '准确率：', accuracy(model(X_app), Y_app) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y\n",
    "# Y_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_app\n",
    "# Y_app.to(device)\n",
    "# accuracy(model(X_app), Y_app)\n",
    "# accuracy(model(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_app2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred2 = (Y_app2 > 0.5).type(torch.int32)\n",
    "# y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准确性验证\n",
    "过拟合/欠拟合\n",
    "- 过拟合：对于已知数据过度拟合，对未知数据预测性差\n",
    "- 欠拟合：对于已知数据拟合不够，对未知数据预测性差\n",
    "  \n",
    "tensor合并\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape, train_y.shape\n",
    "# train_cat = torch.cat([train_x, train_y],dim=1)   # 沿着Dimension 1进行合并\n",
    "# train_cat.shape\n",
    "# train_all.numpy()\n",
    "# np.savetxt('../dataset/test20.csv', train_cat.numpy(),fmt='%.8f',delimiter=',') # 直接覆盖\n",
    "# train_np = np.loadtxt('../dataset/test20.csv', dtype = np.float32, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 4.1 - random_split Mode， charlie\n",
    "# from torch.utils.data import random_split    \n",
    "# def accuracy(y_pred, y_true):\n",
    "#     y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "#     acc = (y_pred == y_true).float().mean()\n",
    "#     return acc\n",
    "\n",
    "# HR_dataset = TensorDataset(X, Y)\n",
    "# test_ds, test_ds = random_split(HR_dataset, [0.8, 0.2]) \n",
    "# HR_dataloader = DataLoader(test_ds, batch_size=batch, shuffle=True)  # shuffle乱序取数\n",
    "# epochMode = 41\n",
    "# if epochMode == 41:  \n",
    "#     for epoch in range( epochs ):\n",
    "#         # for x,y in HR_dataloader:\n",
    "#         for x,y in HR_dataloader:\n",
    "#             y_pred = model(x)\n",
    "#             loss = loss_fn(y_pred, y)\n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#         with torch.no_grad():\n",
    "#             print('epoch: ', epoch, ' loss: ', loss_fn(model(X), Y).data.item() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude: 根据提供的notebook,Claude2对代码的建议和注释如下:\n",
    "1. 数据处理部分可以添加更多注释,说明读取的数据字段含义,以及对数据的检查和处理思路。\n",
    "2. 模型定义部分可以添加注释,说明输入和输出维度的设定依据,网络层数和神经元数量的选择依据等。\n",
    "3. 训练评估部分的注释可以更详细,说明采用的数据分割方式,训练过程中的超参数,以及评估指标的计算方法。\n",
    "4. 模型训练结果可以进行更深入的分析,检查是否存在过拟合或欠拟合,并结合业务目标提出后续优化思路。 \n",
    "5. 可以添加模型效果可视化的代码,如Loss曲线,预测结果示例等,更直观地呈现模型效果。\n",
    "6. 添加模型保存和加载的代码,便于训练后的模型重用。\n",
    "7. 可以尝试不同模型结构或训练策略的比较实验。\n",
    "8. 可以基于代码封装出函数或类,提高代码的复用性和模块化程度。\n",
    "9. 添加类型注释,可以提高代码可读性和健壮性。\n",
    "总体而言,该notebook内容完整,但仍有进一步提升注释、可视化、模块化、模型分析等方面的优化空间。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
