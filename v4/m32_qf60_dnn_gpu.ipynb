{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random\n",
    "# %matplotlib inline\n",
    "\n",
    "# pd.set_option('precision', np.float32)\n",
    "# pd.options.display.float_format = '{:.7g}'.format \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F  # 避免relu和sigmoid的初始化，可以直接调用\n",
    "\n",
    "from importlib import reload \n",
    "from qflib import basic\n",
    "reload(basic)\n",
    "\n",
    "global engine, conn\n",
    "engine = basic.engine()\n",
    "conn = basic.conn(engine)\n",
    "\n",
    "df=pd.DataFrame()  # 初始化空值\n",
    "vTest = 1000\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True  \n",
    "cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( device )\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.caching_allocator_delete\n",
    "#     torch.cuda.empty_cache()  # 释放显存\n",
    "#     print('Memory Allocated', torch.cuda.memory_allocated() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude: 根据提供的notebook,Claude2对代码的建议和注释如下:\n",
    "1. 数据处理部分可以添加更多注释,说明读取的数据字段含义,以及对数据的检查和处理思路。\n",
    "2. 模型定义部分可以添加注释,说明输入和输出维度的设定依据,网络层数和神经元数量的选择依据等。\n",
    "3. 训练评估部分的注释可以更详细,说明采用的数据分割方式,训练过程中的超参数,以及评估指标的计算方法。\n",
    "4. 模型训练结果可以进行更深入的分析,检查是否存在过拟合或欠拟合,并结合业务目标提出后续优化思路。 \n",
    "5. 可以添加模型效果可视化的代码,如Loss曲线,预测结果示例等,更直观地呈现模型效果。\n",
    "6. 添加模型保存和加载的代码,便于训练后的模型重用。\n",
    "7. 可以尝试不同模型结构或训练策略的比较实验。\n",
    "8. 可以基于代码封装出函数或类,提高代码的复用性和模块化程度。\n",
    "9. 添加类型注释,可以提高代码可读性和健壮性。\n",
    "总体而言,该notebook内容完整,但仍有进一步提升注释、可视化、模块化、模型分析等方面的优化空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"SELECT * FROM ds_qf60\"\n",
    "# sql=\"SELECT * FROM ds_qf60_2\"\n",
    "df = pd.read_sql_query(sql, conn, index_col=None)\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294721 entries, 0 to 294720\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   pct_change    294721 non-null  float64\n",
      " 1   diff          294721 non-null  float64\n",
      " 2   bar           294721 non-null  float64\n",
      " 3   jx_days_ud60  294721 non-null  int64  \n",
      " 4   jx_xl_250     294721 non-null  float64\n",
      " 5   jx_xl_120     294721 non-null  float64\n",
      " 6   jx_xl_60      294721 non-null  float64\n",
      " 7   jx_xl_20      294721 non-null  float64\n",
      " 8   jx_xl_10      294721 non-null  float64\n",
      " 9   jx_xl_5       294721 non-null  float64\n",
      " 10  jx_zs_5       294721 non-null  int64  \n",
      " 11  jx_zs_10      294721 non-null  int64  \n",
      " 12  jx_zs_20      294721 non-null  int64  \n",
      " 13  jx_zs_60      294721 non-null  int64  \n",
      " 14  lj_fl_1_3     294721 non-null  float64\n",
      " 15  lj_fl_3_10    294721 non-null  float64\n",
      " 16  lj_fl_5_20    294721 non-null  float64\n",
      " 17  lj_fl_20_60   294721 non-null  float64\n",
      " 18  test20_30     294721 non-null  int64  \n",
      " 19  test10_10     294721 non-null  int64  \n",
      " 20  test20_20     294721 non-null  int64  \n",
      " 21  class0        294721 non-null  int64  \n",
      "dtypes: float64(13), int64(9)\n",
      "memory usage: 49.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (294721, 22))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class0'] = df['test10_10']\n",
    "df.info(), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64),\n",
       " 0    257233\n",
       " 1     37488\n",
       " Name: class0, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class0.unique(), df.class0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([294721, 1]), 294721)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = df.class0.values.reshape(-1,1)  # 转换成 pd type array\n",
    "# Y_data\n",
    "Y = torch.from_numpy(Y_data).type(torch.float32)\n",
    "# Y = torch.from_numpy(Y_data).type(torch.FloatTensor).to(device)\n",
    "Y.shape, Y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294721 entries, 0 to 294720\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   pct_change    294721 non-null  float64\n",
      " 1   diff          294721 non-null  float64\n",
      " 2   bar           294721 non-null  float64\n",
      " 3   jx_days_ud60  294721 non-null  int64  \n",
      " 4   jx_xl_250     294721 non-null  float64\n",
      " 5   jx_xl_120     294721 non-null  float64\n",
      " 6   jx_xl_60      294721 non-null  float64\n",
      " 7   jx_xl_20      294721 non-null  float64\n",
      " 8   jx_xl_10      294721 non-null  float64\n",
      " 9   jx_xl_5       294721 non-null  float64\n",
      " 10  jx_zs_5       294721 non-null  int64  \n",
      " 11  jx_zs_10      294721 non-null  int64  \n",
      " 12  jx_zs_20      294721 non-null  int64  \n",
      " 13  jx_zs_60      294721 non-null  int64  \n",
      " 14  lj_fl_1_3     294721 non-null  float64\n",
      " 15  lj_fl_3_10    294721 non-null  float64\n",
      " 16  lj_fl_5_20    294721 non-null  float64\n",
      " 17  lj_fl_20_60   294721 non-null  float64\n",
      "dtypes: float64(13), int64(5)\n",
      "memory usage: 40.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((294721, 18), None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = ['pct_change', 'diff', 'bar', 'jx_days_ud60', 'jx_xl_250', 'jx_xl_120',\n",
    "       'jx_xl_60', 'jx_xl_20', 'jx_xl_10', 'jx_xl_5', 'jx_zs_5', 'jx_zs_10',\n",
    "       'jx_zs_20', 'jx_zs_60', 'lj_fl_1_3', 'lj_fl_3_10', 'lj_fl_5_20',\n",
    "       'lj_fl_20_60']\n",
    "# X_columns\n",
    "X_data = df[X_columns]  \n",
    "X_data.shape, X_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([294721, 18]), torch.Size([294721, 18]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.from_numpy(X_data.values).type(torch.FloatTensor)\n",
    "X = torch.from_numpy(X_data.values).type(torch.float32)\n",
    "X.shape, X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(18, 64)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(64, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.sigmoid( self.liner_3(x) )\n",
    "        return x\n",
    "\n",
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(18, 256)   # X.size(1)= 20； 定义256个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 32)   # 接着，再定义32个后续中间层\n",
    "        self.liner_4 = nn.Linear(32, 1)     \n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.relu( self.liner_3(x) )\n",
    "        x = F.sigmoid( self.liner_4(x) )\n",
    "        return x\n",
    "\n",
    "# 更加高级语言法，等价于Model\n",
    "class Model_high(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(29, 256)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_4 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.Liner_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([221040, 18]),\n",
       " torch.Size([73681, 18]),\n",
       " torch.Size([221040, 1]),\n",
       " torch.Size([73681, 1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver 4.2 - sklearn mode\n",
    "\n",
    "lr = 0.00012\n",
    "def get_model():\n",
    "    model = Model4()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "model, optim = get_model()\n",
    "model = model.to(device)\n",
    "# model, optim \n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "# batch = 64\n",
    "# batch = 256\n",
    "# batch = 1024\n",
    "# batch = 8192\n",
    "batch = 16384\n",
    "# batch = 32768\n",
    "# batch = 65536\n",
    "# batch = 131072\n",
    "epochs = 20\n",
    "no_of_batches = len(X)//batch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)\n",
    "\n",
    "train_x = torch.from_numpy(train_x.values).type(torch.float32).to(device)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32).to(device)\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_x = torch.from_numpy(test_x.values).type(torch.float32).to(device)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32).to(device)\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)  # 不需要shuffle，减少运算量\n",
    "\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正确率\n",
    "- Sigmoid()是0和1之间的值， 大于0.5为1，否则是0\n",
    "- out1 = (y-pred >0.5).type(torch.int32)  : 转换成0或1\n",
    "- (out1 == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  train_loss:  0.4903  Acc： 0.8726 0  test_loss:  0.4902  Acc： 0.8735\n",
      "epoch:  1  train_loss:  0.3975  Acc： 0.8726 1  test_loss:  0.3968  Acc： 0.8735\n",
      "epoch:  2  train_loss:  0.3965  Acc： 0.8726 2  test_loss:  0.3955  Acc： 0.8735\n",
      "epoch:  3  train_loss:  0.3944  Acc： 0.8726 3  test_loss:  0.3935  Acc： 0.8735\n",
      "epoch:  4  train_loss:  0.394  Acc： 0.8726 4  test_loss:  0.3932  Acc： 0.8735\n",
      "epoch:  5  train_loss:  0.3936  Acc： 0.8726 5  test_loss:  0.3927  Acc： 0.8735\n",
      "epoch:  6  train_loss:  0.3933  Acc： 0.8726 6  test_loss:  0.3923  Acc： 0.8735\n",
      "epoch:  7  train_loss:  0.3929  Acc： 0.8726 7  test_loss:  0.3919  Acc： 0.8735\n",
      "epoch:  8  train_loss:  0.3926  Acc： 0.8726 8  test_loss:  0.3916  Acc： 0.8735\n",
      "epoch:  9  train_loss:  0.3923  Acc： 0.8726 9  test_loss:  0.3913  Acc： 0.8735\n",
      "epoch:  10  train_loss:  0.3919  Acc： 0.8726 10  test_loss:  0.3909  Acc： 0.8735\n",
      "epoch:  11  train_loss:  0.3914  Acc： 0.8726 11  test_loss:  0.3904  Acc： 0.8735\n",
      "epoch:  12  train_loss:  0.3909  Acc： 0.8726 12  test_loss:  0.3899  Acc： 0.8735\n",
      "epoch:  13  train_loss:  0.3904  Acc： 0.8726 13  test_loss:  0.3894  Acc： 0.8735\n",
      "epoch:  14  train_loss:  0.3897  Acc： 0.8726 14  test_loss:  0.3887  Acc： 0.8735\n",
      "epoch:  15  train_loss:  0.3888  Acc： 0.8726 15  test_loss:  0.3878  Acc： 0.8735\n",
      "epoch:  16  train_loss:  0.3879  Acc： 0.8726 16  test_loss:  0.3869  Acc： 0.8735\n",
      "epoch:  17  train_loss:  0.3869  Acc： 0.8726 17  test_loss:  0.3858  Acc： 0.8735\n",
      "epoch:  18  train_loss:  0.386  Acc： 0.8726 18  test_loss:  0.3848  Acc： 0.8735\n",
      "epoch:  19  train_loss:  0.3851  Acc： 0.8726 19  test_loss:  0.3839  Acc： 0.8735\n",
      "CPU times: total: 19 s\n",
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# epochs = 10\n",
    "for epoch in range( epochs ):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch: ', \n",
    "            epoch, ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "            epoch, ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   train_loss:  0.3851  Acc： 0.8726  test_loss:  0.3839  Acc： 0.8735\n"
     ]
    }
   ],
   "source": [
    "# 最后一次计算结果：\n",
    "\n",
    "epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "print('epoch: ', \n",
    "    ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "    ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( loss_fn(model(train_x), train_y).data.item() )\n",
    "# accuracyRate = ((model(train_x).data.numpy()).astype('int') == train_y.numpy().astype('int')).mean()\n",
    "# print(\"训练数据 - 准确率%：\", accuracyRate*100) \n",
    "\n",
    "# print( loss_fn(model(test_x), test_y).data.item() )\n",
    "# accuracyRate = ((model(test_x).data.numpy()).astype('int') == test_y.numpy().astype('int')).mean()\n",
    "# print(\"测试数据 - 准确率%：\", accuracyRate*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准确性验证\n",
    "过拟合/欠拟合\n",
    "- 过拟合：对于已知数据过度拟合，对未知数据预测性差\n",
    "- 欠拟合：对于已知数据拟合不够，对未知数据预测性差\n",
    "  \n",
    "tensor合并\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape, train_y.shape\n",
    "# train_cat = torch.cat([train_x, train_y],dim=1)   # 沿着Dimension 1进行合并\n",
    "# train_cat.shape\n",
    "# train_all.numpy()\n",
    "# np.savetxt('../dataset/test20.csv', train_cat.numpy(),fmt='%.8f',delimiter=',') # 直接覆盖\n",
    "# train_np = np.loadtxt('../dataset/test20.csv', dtype = np.float32, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 4.1 - random_split Mode， charlie\n",
    "# from torch.utils.data import random_split    \n",
    "# def accuracy(y_pred, y_true):\n",
    "#     y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "#     acc = (y_pred == y_true).float().mean()\n",
    "#     return acc\n",
    "\n",
    "# HR_dataset = TensorDataset(X, Y)\n",
    "# test_ds, test_ds = random_split(HR_dataset, [0.8, 0.2]) \n",
    "# HR_dataloader = DataLoader(test_ds, batch_size=batch, shuffle=True)  # shuffle乱序取数\n",
    "# epochMode = 41\n",
    "# if epochMode == 41:  \n",
    "#     for epoch in range( epochs ):\n",
    "#         # for x,y in HR_dataloader:\n",
    "#         for x,y in HR_dataloader:\n",
    "#             y_pred = model(x)\n",
    "#             loss = loss_fn(y_pred, y)\n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#         with torch.no_grad():\n",
    "#             print('epoch: ', epoch, ' loss: ', loss_fn(model(X), Y).data.item() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
