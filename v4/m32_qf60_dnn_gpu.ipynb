{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random\n",
    "# %matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F  # 避免relu和sigmoid的初始化，可以直接调用\n",
    "\n",
    "from importlib import reload \n",
    "from qflib import basic\n",
    "reload(basic)\n",
    "\n",
    "global engine, conn\n",
    "engine = basic.engine()\n",
    "conn = basic.conn(engine)\n",
    "\n",
    "df=pd.DataFrame()  # 初始化空值\n",
    "# pd.options.display.float_format = '{:.7g}'.format \n",
    "vTest = 1000\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True  \n",
    "cudnn.deterministic = True\n",
    "\n",
    "xl_01dgree = 0.001745 # 0.1度 \n",
    "xl_02dgree = 0.003490 # 0.2度 \n",
    "xl_03dgree = 0.005230 # 0.3度\n",
    "xl_dgree = xl_03dgree\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( device )\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.caching_allocator_delete\n",
    "#     torch.cuda.empty_cache()  # 释放显存\n",
    "#     print('Memory Allocated', torch.cuda.memory_allocated() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"SELECT * FROM ds_qf60\"\n",
    "# sql=\"SELECT * FROM ds_qf60_2\"\n",
    "df = pd.read_sql_query(sql, conn, index_col=None)\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292325 entries, 0 to 292324\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   pct_change    292325 non-null  float64\n",
      " 1   diff          292325 non-null  float64\n",
      " 2   dea           292325 non-null  float64\n",
      " 3   bar           292325 non-null  float64\n",
      " 4   jx_days_ud60  292325 non-null  int64  \n",
      " 5   jx_xl_250     292325 non-null  float64\n",
      " 6   jx_xl_120     292325 non-null  float64\n",
      " 7   jx_xl_60      292325 non-null  float64\n",
      " 8   jx_xl_20      292325 non-null  float64\n",
      " 9   jx_xl_10      292325 non-null  float64\n",
      " 10  jx_xl_5       292325 non-null  float64\n",
      " 11  jx_zs_5       292325 non-null  int64  \n",
      " 12  jx_zs_10      292325 non-null  int64  \n",
      " 13  jx_zs_20      292325 non-null  int64  \n",
      " 14  jx_zs_60      292325 non-null  int64  \n",
      " 15  lj_fl_1_3     292325 non-null  float64\n",
      " 16  lj_fl_3_10    292325 non-null  float64\n",
      " 17  lj_fl_5_20    292325 non-null  float64\n",
      " 18  lj_fl_20_60   292325 non-null  float64\n",
      " 19  test20_30     292325 non-null  int64  \n",
      " 20  test10_10     292325 non-null  int64  \n",
      " 21  test20_20     292325 non-null  int64  \n",
      " 22  test5_8       292325 non-null  float64\n",
      " 23  class0        292325 non-null  int64  \n",
      "dtypes: float64(15), int64(9)\n",
      "memory usage: 53.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (292325, 24))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 确定训练的目标 \"\"\"\n",
    "# df['class0'] = df['test5_8']\n",
    "df['class0'] = df['test10_10']\n",
    "# df['class0'] = df['test20_20']\n",
    "# df['class0'] = df['test20_30']\n",
    "df.info(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64),\n",
       " 0    246721\n",
       " 1     45604\n",
       " Name: class0, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class0.unique(), df.class0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([292325, 1]), 292325)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = df.class0.values.reshape(-1,1)  # 转换成 pd type array\n",
    "Y = torch.from_numpy(Y_data).type(torch.float32)\n",
    "Y.shape, Y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([292325, 19]), torch.Size([292325, 19]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = ['pct_change', \n",
    "             'diff', 'dea', 'bar', \n",
    "             'jx_days_ud60', \n",
    "             'jx_xl_250', 'jx_xl_120','jx_xl_60', \n",
    "             'jx_xl_20', 'jx_xl_10', 'jx_xl_5', \n",
    "             'jx_zs_5', 'jx_zs_10','jx_zs_20', 'jx_zs_60', \n",
    "             'lj_fl_1_3', 'lj_fl_3_10', 'lj_fl_5_20','lj_fl_20_60']\n",
    "X_data = df[X_columns]  \n",
    "X = torch.from_numpy(X_data.values).type(torch.float32)\n",
    "X.shape, X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(19, 64)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(64, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.sigmoid( self.liner_3(x) )\n",
    "        return x\n",
    "\n",
    "class Model4A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(19, 128)   # X.size(1)= 20； 定义256个后续中间层\n",
    "        self.liner_2 = nn.Linear(128, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 32)   # 接着，再定义32个后续中间层\n",
    "        self.liner_4 = nn.Linear(32, 1)     \n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.relu( self.liner_3(x) )\n",
    "        x = F.sigmoid( self.liner_4(x) )\n",
    "        return x\n",
    "    \n",
    "class Model4B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(19, 128)   # X.size(1)= 20； 定义256个后续中间层\n",
    "        self.liner_2 = nn.Linear(128, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 128)  # 接着，再定义128个后续中间层\n",
    "        self.liner_4 = nn.Linear(128, 32)   # 接着，再定义32个后续中间层\n",
    "        self.liner_5 = nn.Linear(32, 1)     \n",
    "    def forward(self, input):\n",
    "        x = F.relu( self.liner_1(input) )\n",
    "        x = F.relu( self.liner_2(x) )\n",
    "        x = F.relu( self.liner_3(x) )\n",
    "        x = F.relu( self.liner_4(x) )\n",
    "        x = F.sigmoid( self.liner_5(x) )\n",
    "        return x\n",
    "\n",
    "# 更加高级语言法，等价于Model\n",
    "class Model_high(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # 继承父类中所有的属性\n",
    "        self.liner_1 = nn.Linear(29, 256)   # X.size(1)= 20； 定义64个后续中间层\n",
    "        self.liner_2 = nn.Linear(256, 128)   # 接着，再定义64个后续中间层\n",
    "        self.liner_3 = nn.Linear(128, 64)   # 接着，再定义64个后续中间层\n",
    "        self.liner_4 = nn.Linear(64, 1)   # 接着，再定义64个后续中间层\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.Liner_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Liner_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([219243, 19]),\n",
       " torch.Size([73082, 19]),\n",
       " torch.Size([219243, 1]),\n",
       " torch.Size([73082, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver 4.2 - sklearn mode\n",
    "\n",
    "lr = 0.00012\n",
    "def get_model():\n",
    "    model = Model4B()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "model, optim = get_model()\n",
    "model = model.to(device)\n",
    "# model, optim \n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "# batch = 64\n",
    "# batch = 1024\n",
    "batch = 8192\n",
    "# batch = 16384\n",
    "# batch = 32768\n",
    "epochs = 10\n",
    "no_of_batches = len(X)//batch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)\n",
    "\n",
    "train_x = torch.from_numpy(train_x.values).type(torch.float32).to(device)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32).to(device)\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_x = torch.from_numpy(test_x.values).type(torch.float32).to(device)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32).to(device)\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch, shuffle=False)  # 不需要shuffle，减少运算量\n",
    "\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正确率\n",
    "- Sigmoid()是0和1之间的值， 大于0.5为1，否则是0\n",
    "- out1 = (y-pred >0.5).type(torch.int32)  : 转换成0或1\n",
    "- (out1 == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  train_loss:  0.5617  Acc： 0.8443 0  test_loss:  0.562  Acc： 0.8432\n",
      "epoch:  1  train_loss:  0.4672  Acc： 0.8443 1  test_loss:  0.4679  Acc： 0.8432\n",
      "epoch:  2  train_loss:  0.4342  Acc： 0.8443 2  test_loss:  0.4355  Acc： 0.8432\n",
      "epoch:  3  train_loss:  0.4335  Acc： 0.8443 3  test_loss:  0.4349  Acc： 0.8432\n",
      "epoch:  4  train_loss:  0.4328  Acc： 0.8443 4  test_loss:  0.4341  Acc： 0.8432\n",
      "epoch:  5  train_loss:  0.4318  Acc： 0.8443 5  test_loss:  0.4331  Acc： 0.8432\n",
      "epoch:  6  train_loss:  0.4307  Acc： 0.8443 6  test_loss:  0.432  Acc： 0.8432\n",
      "epoch:  7  train_loss:  0.4296  Acc： 0.8442 7  test_loss:  0.4309  Acc： 0.8431\n",
      "epoch:  8  train_loss:  0.4288  Acc： 0.8441 8  test_loss:  0.4299  Acc： 0.8431\n",
      "epoch:  9  train_loss:  0.4279  Acc： 0.844 9  test_loss:  0.4291  Acc： 0.843\n",
      "CPU times: total: 9.45 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# epochs = 10\n",
    "for epoch in range( epochs ):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch: ', \n",
    "            epoch, ' train_loss: ', round(epoch_loss,4), ' Acc：', round(epoch_accuracy.item(),4),\n",
    "            epoch, ' test_loss: ', round(epoch_test_loss,4), ' Acc：', round(epoch_test_accuracy.item(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8430, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8441, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m, test_m, train_n, test_n = train_test_split(X_data, Y_data, shuffle=True)\n",
    "\n",
    "# train_x = torch.from_numpy(train_x.values).type(torch.float32).to(device)\n",
    "# train_y = torch.from_numpy(train_y).type(torch.float32).to(device)\n",
    "# train_ds = TensorDataset(train_x, train_y)\n",
    "# train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)  # 需要shuffle，乱序执行\n",
    "\n",
    "test_m = torch.from_numpy(test_m.values).type(torch.float32).to(device)\n",
    "test_n = torch.from_numpy(test_n).type(torch.float32).to(device)\n",
    "accuracy(model(test_m), test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 模型保存 '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 模型保存 \"\"\"\n",
    "# torch.save( model, '../model/test5-8.pth')\n",
    "# path = '../model/test5-8'\n",
    "# torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optim.state_dict(),\n",
    "#            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = []\n",
    "# for i in range(0,X_app.size(0)):\n",
    "#     list1.append( random.randint(1,1) )\n",
    "# len(list1)\n",
    "# Y_app = torch.tensor( list1 )\n",
    "# Y_app.to(device)\n",
    "# Y_app.reshape(-1,1).size(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ts_code, trade_date, pct_change, diff, dea, bar, jx_days_ud60, jx_xl_250, jx_xl_120, jx_xl_60,jx_xl_20, jx_xl_10, jx_xl_5, jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, sz_max_5, sz_max_10, sz_max_20  from day_zhibiao where trade_date>='20230601' and sz_max_10>10 and jx_days_ud60 > 20 and jx_days_ud60 < 60 and jx_xl_60>-0.00523 and  jx_xl_20>0 \n",
      "(651, 24)\n",
      "     ts_code trade_date  sz_max_10  sz_max_20\n",
      "0  000510.SZ   20230613    11.6554    11.6554\n",
      "1  000510.SZ   20230612    11.2795    11.2795\n",
      "2  000561.SZ   20230602    14.5766    24.0086\n",
      "X_app:  torch.Size([651, 19]) <built-in method size of Tensor object at 0x0000019A893D0A40>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 手工取数据: 测试(1) \"\"\"\n",
    "column_str = 'ts_code, trade_date, pct_change, diff, dea, bar, jx_days_ud60, \\\n",
    "jx_xl_250, jx_xl_120, jx_xl_60,\\\n",
    "jx_xl_20, jx_xl_10, jx_xl_5, \\\n",
    "jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,\\\n",
    "lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, \\\n",
    "sz_max_5, sz_max_10, sz_max_20 '\n",
    "# print(column_str)\n",
    "\n",
    "sql_new= \"SELECT \" + column_str +\" \\\n",
    "from day_zhibiao \\\n",
    "where trade_date>='20230601' and sz_max_10>10 and \\\n",
    "jx_days_ud60 > 20 and jx_days_ud60 < 60 and \\\n",
    "jx_xl_60>-\"+str(xl_dgree)+\" and  \\\n",
    "jx_xl_20>0 \"\n",
    "print(sql_new)\n",
    "df_new = pd.read_sql_query(sql_new, conn)\n",
    "print( df_new.shape )\n",
    "# print( df_new[ df_new['sz_max_5']>8 ].head(3) )\n",
    "print( df_new[ df_new['sz_max_10']>10 ][['ts_code','trade_date','sz_max_10','sz_max_20']].head(3) )\n",
    "\n",
    "X_columns = ['pct_change', \n",
    "             'diff', 'dea', 'bar', \n",
    "             'jx_days_ud60', \n",
    "             'jx_xl_250', 'jx_xl_120','jx_xl_60', \n",
    "             'jx_xl_20', 'jx_xl_10', 'jx_xl_5', \n",
    "             'jx_zs_5', 'jx_zs_10','jx_zs_20', 'jx_zs_60', \n",
    "             'lj_fl_1_3', 'lj_fl_3_10', 'lj_fl_5_20','lj_fl_20_60']\n",
    "df_app = df_new[X_columns]\n",
    "X_app = torch.from_numpy(df_app.values).type(torch.float32).to(device)\n",
    "\n",
    "# print( df_app.head(3) )\n",
    "print('X_app: ', X_app.shape, X_app.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([651, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in range(0,X_app.size(0)):\n",
    "    list1.append( 1.0 )\n",
    "Y_app = torch.tensor( list1).type(torch.float32).reshape(-1,1).to(device)\n",
    "Y_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([651, 19]), torch.Size([651, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_app = torch.tensor( list1).type(torch.float32)\n",
    "X_app.shape, Y_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '准确率：', accuracy(model(X_app), Y_app) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y\n",
    "Y_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_app\n",
    "# Y_app.to(device)\n",
    "accuracy(model(X_app), Y_app)\n",
    "# accuracy(model(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ts_code, trade_date, pct_change, diff, dea, bar, jx_days_ud60, jx_xl_250, jx_xl_120, jx_xl_60,jx_xl_20, jx_xl_10, jx_xl_5, jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, sz_max_5, sz_max_10, sz_max_20  from day_zhibiao where trade_date>='20230601' and sz_max_10>10 and jx_days_ud60 > 20 and jx_days_ud60 < 60 and jx_xl_60>-0.00523 and  jx_xl_20>0 \n",
      "(651, 24)\n",
      "     ts_code trade_date  pct_change      diff       dea       bar  \\\n",
      "0  000510.SZ   20230613     -0.3367 -0.048761 -0.067651  0.037780   \n",
      "1  000510.SZ   20230612      2.5907 -0.062555 -0.072373  0.019636   \n",
      "2  000561.SZ   20230602      0.8649  0.023673 -0.026637  0.100619   \n",
      "\n",
      "   jx_days_ud60  jx_xl_250  jx_xl_120  jx_xl_60  ...  jx_zs_10  jx_zs_20  \\\n",
      "0            47  -0.000142   0.000122 -0.001376  ...         3         2   \n",
      "1            46  -0.000129   0.000122 -0.000825  ...         2         1   \n",
      "2            47   0.001256   0.000402 -0.002363  ...         3        13   \n",
      "\n",
      "   jx_zs_60  lj_fl_1_3  lj_fl_3_10  lj_fl_5_20  lj_fl_20_60  sz_max_5  \\\n",
      "0         0   0.877151     1.12928    0.856350     0.670559  11.65540   \n",
      "1         0   1.555420     1.05583    0.737054     0.734229  11.27950   \n",
      "2         0   1.213370     1.33650    1.097930     0.525210   5.57342   \n",
      "\n",
      "   sz_max_10  sz_max_20  \n",
      "0    11.6554    11.6554  \n",
      "1    11.2795    11.2795  \n",
      "2    14.5766    24.0086  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "X_app:  torch.Size([651, 19]) torch.Size([651, 19])\n",
      "找出数量：  []\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 手工取数据: 测试 (2) \"\"\"\n",
    "def model_app(X_app):\n",
    "    Y_app = model(X_app)\n",
    "    Y_app2 = Y_app.to('cpu').detach()\n",
    "    y_app = Y_app2.numpy() \n",
    "    acc_num =  np.argwhere(y_app>0.5)\n",
    "    return Y_app2, acc_num\n",
    "\n",
    "column_str = 'ts_code, trade_date, pct_change, diff, dea, bar, jx_days_ud60, \\\n",
    "jx_xl_250, jx_xl_120, jx_xl_60,\\\n",
    "jx_xl_20, jx_xl_10, jx_xl_5, \\\n",
    "jx_zs_5, jx_zs_10, jx_zs_20, jx_zs_60,\\\n",
    "lj_fl_1_3, lj_fl_3_10, lj_fl_5_20, lj_fl_20_60, \\\n",
    "sz_max_5, sz_max_10, sz_max_20 '\n",
    "# print(column_str)\n",
    "\n",
    "sql_new= \"SELECT \" + column_str +\" \\\n",
    "from day_zhibiao \\\n",
    "where trade_date>='20230601' and sz_max_10>10 and \\\n",
    "jx_days_ud60 > 20 and jx_days_ud60 < 60 and \\\n",
    "jx_xl_60>-\"+str(xl_dgree)+\" and  \\\n",
    "jx_xl_20>0 \"\n",
    "print(sql_new)\n",
    "df_new = pd.read_sql_query(sql_new, conn)\n",
    "print( df_new.shape )\n",
    "# print( df_new[ df_new['sz_max_5']>8 ].head(3) )\n",
    "print( df_new[ df_new['sz_max_10']>10 ].head(3) )\n",
    "\n",
    "X_columns = ['pct_change', \n",
    "             'diff', 'dea', 'bar', \n",
    "             'jx_days_ud60', \n",
    "             'jx_xl_250', 'jx_xl_120','jx_xl_60', \n",
    "             'jx_xl_20', 'jx_xl_10', 'jx_xl_5', \n",
    "             'jx_zs_5', 'jx_zs_10','jx_zs_20', 'jx_zs_60', \n",
    "             'lj_fl_1_3', 'lj_fl_3_10', 'lj_fl_5_20','lj_fl_20_60']\n",
    "df_app = df_new[X_columns]\n",
    "X_app = torch.from_numpy(df_app.values).type(torch.float32).to(device)\n",
    "# print( df_app.head(3) )\n",
    "print('X_app: ', X_app.shape, X_app.size() )\n",
    "\n",
    "Y_app2, acc_num = model_app(X_app) \n",
    "print('找出数量： ', acc_num )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_app2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred2 = (Y_app2 > 0.5).type(torch.int32)\n",
    "# y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准确性验证\n",
    "过拟合/欠拟合\n",
    "- 过拟合：对于已知数据过度拟合，对未知数据预测性差\n",
    "- 欠拟合：对于已知数据拟合不够，对未知数据预测性差\n",
    "  \n",
    "tensor合并\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape, train_y.shape\n",
    "# train_cat = torch.cat([train_x, train_y],dim=1)   # 沿着Dimension 1进行合并\n",
    "# train_cat.shape\n",
    "# train_all.numpy()\n",
    "# np.savetxt('../dataset/test20.csv', train_cat.numpy(),fmt='%.8f',delimiter=',') # 直接覆盖\n",
    "# train_np = np.loadtxt('../dataset/test20.csv', dtype = np.float32, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 4.1 - random_split Mode， charlie\n",
    "# from torch.utils.data import random_split    \n",
    "# def accuracy(y_pred, y_true):\n",
    "#     y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "#     acc = (y_pred == y_true).float().mean()\n",
    "#     return acc\n",
    "\n",
    "# HR_dataset = TensorDataset(X, Y)\n",
    "# test_ds, test_ds = random_split(HR_dataset, [0.8, 0.2]) \n",
    "# HR_dataloader = DataLoader(test_ds, batch_size=batch, shuffle=True)  # shuffle乱序取数\n",
    "# epochMode = 41\n",
    "# if epochMode == 41:  \n",
    "#     for epoch in range( epochs ):\n",
    "#         # for x,y in HR_dataloader:\n",
    "#         for x,y in HR_dataloader:\n",
    "#             y_pred = model(x)\n",
    "#             loss = loss_fn(y_pred, y)\n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#         with torch.no_grad():\n",
    "#             print('epoch: ', epoch, ' loss: ', loss_fn(model(X), Y).data.item() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude: 根据提供的notebook,Claude2对代码的建议和注释如下:\n",
    "1. 数据处理部分可以添加更多注释,说明读取的数据字段含义,以及对数据的检查和处理思路。\n",
    "2. 模型定义部分可以添加注释,说明输入和输出维度的设定依据,网络层数和神经元数量的选择依据等。\n",
    "3. 训练评估部分的注释可以更详细,说明采用的数据分割方式,训练过程中的超参数,以及评估指标的计算方法。\n",
    "4. 模型训练结果可以进行更深入的分析,检查是否存在过拟合或欠拟合,并结合业务目标提出后续优化思路。 \n",
    "5. 可以添加模型效果可视化的代码,如Loss曲线,预测结果示例等,更直观地呈现模型效果。\n",
    "6. 添加模型保存和加载的代码,便于训练后的模型重用。\n",
    "7. 可以尝试不同模型结构或训练策略的比较实验。\n",
    "8. 可以基于代码封装出函数或类,提高代码的复用性和模块化程度。\n",
    "9. 添加类型注释,可以提高代码可读性和健壮性。\n",
    "总体而言,该notebook内容完整,但仍有进一步提升注释、可视化、模块化、模型分析等方面的优化空间。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
